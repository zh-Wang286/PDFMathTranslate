#!/usr/bin/env python3
"""
PDFç¿»è¯‘ç»Ÿè®¡ç³»ç»Ÿæµ‹è¯•è„šæœ¬

æµ‹è¯•æ–°çš„ç»Ÿè®¡ç®¡ç†ç³»ç»Ÿæ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
"""

import sys
import os
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pdf2zh.statistics import PDFTranslationStatistics, perform_pre_analysis, collect_runtime_stats
from pdf2zh.doclayout import OnnxModel


def test_statistics_class():
    """æµ‹è¯•PDFTranslationStatisticsç±»çš„åŸºæœ¬åŠŸèƒ½"""
    print("=" * 50)
    print("æµ‹è¯• PDFTranslationStatistics ç±»")
    print("=" * 50)
    
    # åˆ›å»ºç»Ÿè®¡å¯¹è±¡
    stats = PDFTranslationStatistics()
    
    # æµ‹è¯•è®¾ç½®è¾“å…¥æ–‡ä»¶
    stats.set_input_files(["test.pdf"])
    assert stats.input_files == ["test.pdf"]
    print("âœ“ è®¾ç½®è¾“å…¥æ–‡ä»¶æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•è®¾ç½®é¢„åˆ†ææ•°æ®
    mock_analysis_data = {
        "page_count": 5,
        "total_paragraph_count": 50,
        "total_paragraph_tokens": 1000,
        "total_table_cell_count": 20,
        "total_table_tokens": 200,
        "pages": {
            0: {"paragraph_count": 10, "paragraph_token_count": 200, "table_count": 1, "table_cell_count": 4, "table_token_count": 40},
            1: {"paragraph_count": 12, "paragraph_token_count": 240, "table_count": 0, "table_cell_count": 0, "table_token_count": 0},
        }
    }
    stats.set_pre_analysis_data(mock_analysis_data)
    assert stats.pre_stats["page_count"] == 5
    assert stats.pre_stats["total_paragraph_count"] == 50
    print("âœ“ è®¾ç½®é¢„åˆ†ææ•°æ®æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ—¶é—´ä¼°ç®—
    estimated_time = stats.estimate_translation_time(is_reasoning=False)
    assert estimated_time > 0
    print(f"âœ“ é»˜è®¤æ¨¡å¼æ—¶é—´ä¼°ç®—: {estimated_time:.2f}ç§’")
    
    reasoning_time = stats.estimate_translation_time(is_reasoning=True)
    assert reasoning_time > estimated_time  # æ¨ç†æ¨¡å¼åº”è¯¥éœ€è¦æ›´å¤šæ—¶é—´
    print(f"âœ“ æ¨ç†æ¨¡å¼æ—¶é—´ä¼°ç®—: {reasoning_time:.2f}ç§’")
    
    # æµ‹è¯•è¿è¡Œæ—¶ç»Ÿè®¡è·Ÿè¸ª
    stats.start_runtime_tracking()
    stats.start_translation_tracking()
    
    # æ¨¡æ‹Ÿä¸€äº›å»¶è¿Ÿ
    import time
    time.sleep(0.1)
    
    stats.end_translation_tracking()
    stats.end_runtime_tracking()
    
    assert stats.runtime_stats["total_time_seconds"] > 0
    assert stats.runtime_stats["translation_time_seconds"] > 0
    print("âœ“ è¿è¡Œæ—¶ç»Ÿè®¡è·Ÿè¸ªæµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    mock_token_stats = {
        "translation_count": 10,
        "prompt_tokens": 500,
        "completion_tokens": 300,
        "total_tokens": 800,
    }
    stats.update_token_stats(mock_token_stats)
    assert stats.runtime_stats["llm_call_count"] == 10
    print("âœ“ Tokenç»Ÿè®¡æ›´æ–°æµ‹è¯•é€šè¿‡")
    
    mock_paragraph_stats = {
        "total_paragraphs": 50,
        "translated": 40,
        "skipped_empty": 5,
        "skipped_formula": 3,
        "skipped_no_text": 2,
    }
    stats.update_paragraph_stats(mock_paragraph_stats)
    assert stats.runtime_stats["paragraph_total"] == 50
    assert stats.runtime_stats["paragraph_translated"] == 40
    print("âœ“ æ®µè½ç»Ÿè®¡æ›´æ–°æµ‹è¯•é€šè¿‡")
    
    mock_table_stats = {
        "total_cells": 20,
        "translated": 15,
        "skipped_empty": 3,
        "skipped_no_text": 2,
    }
    stats.update_table_stats(mock_table_stats)
    assert stats.runtime_stats["table_cell_total"] == 20
    assert stats.runtime_stats["table_cell_translated"] == 15
    print("âœ“ è¡¨æ ¼ç»Ÿè®¡æ›´æ–°æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•ç”ŸæˆæŠ¥å‘Š
    with tempfile.TemporaryDirectory() as temp_dir:
        log_file = stats.generate_report_log(temp_dir)
        assert os.path.exists(log_file)
        print(f"âœ“ æŠ¥å‘Šç”Ÿæˆæµ‹è¯•é€šè¿‡: {log_file}")
        
        # æ£€æŸ¥æŠ¥å‘Šå†…å®¹
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()
            assert "PDF Translation Statistics Report" in content
            assert "æ€»é¡µæ•°: 5" in content
            assert "æ€»æ®µè½æ•°: 50" in content
            print("âœ“ æŠ¥å‘Šå†…å®¹éªŒè¯é€šè¿‡")
    
    print("\nâœ… PDFTranslationStatistics ç±»æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼\n")


def test_estimation_summary():
    """æµ‹è¯•ä¼°ç®—æ•°æ®æ‘˜è¦åŠŸèƒ½"""
    print("=" * 50)
    print("æµ‹è¯•ä¼°ç®—æ•°æ®æ‘˜è¦åŠŸèƒ½")
    print("=" * 50)
    
    stats = PDFTranslationStatistics()
    
    # è®¾ç½®æµ‹è¯•æ•°æ®
    mock_analysis_data = {
        "page_count": 3,
        "total_paragraph_count": 30,
        "total_paragraph_tokens": 600,
        "total_table_cell_count": 10,
        "total_table_tokens": 100,
        "pages": {}
    }
    stats.set_pre_analysis_data(mock_analysis_data)
    stats.estimate_translation_time(is_reasoning=False)
    
    summary = stats.get_estimation_summary()
    
    assert summary["content_stats"]["pages"] == 3
    assert summary["content_stats"]["paragraphs"] == 30
    assert summary["token_estimation"]["input_tokens"] > 0
    assert summary["token_estimation"]["output_tokens"] > 0
    assert summary["time_estimation"]["estimated_seconds"] > 0
    
    print("âœ“ ä¼°ç®—æ•°æ®æ‘˜è¦æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ¨ç†æ¨¡å¼
    stats.estimate_translation_time(is_reasoning=True)
    reasoning_summary = stats.get_estimation_summary()
    
    assert reasoning_summary["time_estimation"]["is_reasoning_mode"] == True
    assert reasoning_summary["token_estimation"]["output_tokens"] > summary["token_estimation"]["output_tokens"]
    
    print("âœ“ æ¨ç†æ¨¡å¼ä¼°ç®—æ•°æ®æ‘˜è¦æµ‹è¯•é€šè¿‡")
    
    print("\nâœ… ä¼°ç®—æ•°æ®æ‘˜è¦åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼\n")


def test_runtime_summary():
    """æµ‹è¯•è¿è¡Œæ—¶æ•°æ®æ‘˜è¦åŠŸèƒ½"""
    print("=" * 50)
    print("æµ‹è¯•è¿è¡Œæ—¶æ•°æ®æ‘˜è¦åŠŸèƒ½")
    print("=" * 50)
    
    stats = PDFTranslationStatistics()
    
    # æ¨¡æ‹Ÿè¿è¡Œæ—¶æ•°æ®
    stats.start_runtime_tracking()
    import time
    time.sleep(0.05)
    stats.end_runtime_tracking()
    
    # æ›´æ–°å„ç§ç»Ÿè®¡ä¿¡æ¯
    stats.update_token_stats({
        "translation_count": 5,
        "prompt_tokens": 250,
        "completion_tokens": 150,
        "total_tokens": 400,
    })
    
    stats.update_paragraph_stats({
        "total_paragraphs": 25,
        "translated": 20,
        "skipped_empty": 3,
        "skipped_formula": 1,
        "skipped_no_text": 1,
    })
    
    stats.update_table_stats({
        "total_cells": 8,
        "translated": 6,
        "skipped_empty": 1,
        "skipped_no_text": 1,
    })
    
    runtime_summary = stats.get_runtime_summary()
    
    assert runtime_summary["time_stats"]["total_time"] > 0
    assert runtime_summary["llm_stats"]["call_count"] == 5
    assert runtime_summary["llm_stats"]["total_tokens"] == 400
    assert runtime_summary["translation_stats"]["paragraphs"]["total"] == 25
    assert runtime_summary["translation_stats"]["paragraphs"]["translated"] == 20
    assert runtime_summary["translation_stats"]["table_cells"]["total"] == 8
    assert runtime_summary["translation_stats"]["table_cells"]["translated"] == 6
    
    print("âœ“ è¿è¡Œæ—¶æ•°æ®æ‘˜è¦æµ‹è¯•é€šè¿‡")
    print("\nâœ… è¿è¡Œæ—¶æ•°æ®æ‘˜è¦åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼\n")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹æµ‹è¯•PDFç¿»è¯‘ç»Ÿè®¡ç³»ç»Ÿ...")
    print("=" * 80)
    
    try:
        test_statistics_class()
        test_estimation_summary()
        test_runtime_summary()
        
        print("=" * 80)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–°çš„ç»Ÿè®¡ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
        print("=" * 80)
        
        return 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main()) 